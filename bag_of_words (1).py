# -*- coding: utf-8 -*-
"""bag of words.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ee-qrD_q4xMmbdBhsoq_8F_szVKDzB__
"""

import cv2
import numpy as np
import os
import matplotlib.pyplot as plt
import random
import pylab as pl
from sklearn.metrics import confusion_matrix,accuracy_score

from google.colab import drive
drive.mount('/content/drive')

train_path="/content/drive/MyDrive/mini project/Yoke_images/train"
class_names=os.listdir(train_path)

def img_list(path):
    y= (os.path.join(path,f) for f in os.listdir(path))
    x= (os.path.basename(path) for i in os.listdir(path))
    return y,x

image_paths=[]
image_classes=[]
D=[]
for training_name in class_names:
    dir_=os.path.join(train_path,training_name)
    class_path,img_class=img_list(dir_)
    image_paths+=class_path
    image_classes+=img_class

for i in range(len(image_classes)):
  if(image_classes[i]=="DEFECTED"):
    image_classes[i]=0
  else:
    image_classes[i]=1
print(image_classes)

for i in range(len(image_paths)):
    D.append((image_paths[i],image_classes[i]))

dataset = D
random.shuffle(dataset)
train = dataset[:92]
test = dataset[92:]

image_paths, y_train = zip(*train)
image_paths_test, y_test = zip(*test)

"""ORB"""

des_list=[]
orb=cv2.ORB_create()
im=cv2.imread(image_paths[1])
plt.imshow(im)

def draw_keypoints(vis, keypoints, color = (0, 0, 255)):
    for kp in keypoints:
            x, y = kp.pt
            plt.imshow(cv2.circle(vis, (int(x), int(y)), 2, color))
kp = orb.detect(im,None)
kp, des = orb.compute(im, kp)
img=draw_keypoints(im,kp)

for image_pat in image_paths:
    im=cv2.imread(image_pat)
    kp=orb.detect(im,None)
    keypoints,descriptor= orb.compute(im, kp)
    des_list.append((image_pat,descriptor))

descriptors=des_list[0][1]
for image_path,descriptor in des_list[1:]:
    descriptors=np.vstack((descriptors,descriptor))

descriptors.shape

descriptors_float=descriptors.astype(float)

from scipy.cluster.vq import kmeans,vq
k=200
voc,variance=kmeans(descriptors_float,k,1)

im_features=np.zeros((len(image_paths),k),"float32")
for i in range(len(image_paths)):
    words,distance=vq(des_list[i][1],voc)
    for w in words:
        im_features[i][w]+=1

from sklearn.preprocessing import StandardScaler
stdslr=StandardScaler().fit(im_features)
im_features=stdslr.transform(im_features)

from sklearn.svm import LinearSVC
clf=LinearSVC(max_iter=80000)
clf.fit(im_features,np.array(y_train))
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=80000,
          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
          verbose=0)
des_list_test=[]
for image_pat in image_paths_test:
    image=cv2.imread(image_pat)
    kp=orb.detect(image,None)
    keypoints_test,descriptor_test= orb.compute(image, kp)
    des_list_test.append((image_pat,descriptor_test))

from scipy.cluster.vq import vq
test_features=np.zeros((len(image_paths_test),k),"float32")
for i in range(len(image_paths_test)):
    words,distance=vq(des_list_test[i][1],voc)
    for w in words:
        test_features[i][w]+=1

test_features

test_features=stdslr.transform(test_features)

true_classes=[]
for i in y_test:
    if i==1:
        true_classes.append("OK")
    else:
        true_classes.append("DEFECTED")
predict_classes=[]
for i in clf.predict(test_features):
    if i==1:
        predict_classes.append("OK")
    else:
        predict_classes.append("DEFECTED")

print(true_classes)
print(predict_classes)
clf.predict(test_features)
accuracy=accuracy_score(true_classes,predict_classes)
print(accuracy)

from sklearn.metrics import confusion_matrix
import seaborn as sns
cm = confusion_matrix(true_classes, predict_classes)
fig, ax = plt.subplots(figsize=(6,6))
sns.set(font_scale=1.6)
sns.heatmap(cm, annot=True, ax=ax)

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn import metrics 
xtrain,xtest,ytrain,ytest=train_test_split(im_features,y_train,test_size=0.1,random_state=1)
gnb = GaussianNB()
gnb.fit(xtrain, ytrain)
y_pred = gnb.predict(xtest) 
print('---------------NAIVE BAYES OUTPUT---------------\n')
print("Gaussian Naive Bayes model accuracy(in %):", metrics.accuracy_score(ytest, y_pred))
print('Prediction is : ',class_names[y_pred[2]])
print('Original is : ',class_names[ytest[2]])

NB_true_classes=[]
for i in ytest:
    if i==1:
        NB_true_classes.append("OK")
    else:
        NB_true_classes.append("DEFECTED")
NB_predict_classes=[]
for i in gnb.predict(xtest):
    if i==1:
        NB_predict_classes.append("OK")
    else:
        NB_predict_classes.append("DEFECTED")

print(NB_true_classes)
print(NB_predict_classes)
from sklearn.metrics import confusion_matrix
import seaborn as sns
cm = confusion_matrix(NB_true_classes, NB_predict_classes)
fig, ax = plt.subplots(figsize=(6,6))
sns.set(font_scale=1.6)
sns.heatmap(cm, annot=True, ax=ax)

from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification

clf1=RandomForestClassifier(n_estimators=100, random_state=30)
clf1.fit(im_features,np.array(y_train))

RF_true_classes=[]
for i in y_test:
    if i==1:
        RF_true_classes.append("OK")
    else:
        RF_true_classes.append("DEFECTED")
RF_predict_classes=[]
for i in clf1.predict(test_features):
    if i==1:
        RF_predict_classes.append("OK")
    else:
        RF_predict_classes.append("DEFECTED")

accuracy=accuracy_score(RF_true_classes,RF_predict_classes)
print(accuracy)

print(NB_true_classes)
print(NB_predict_classes)
from sklearn.metrics import confusion_matrix
import seaborn as sns
cm = confusion_matrix(NB_true_classes, NB_predict_classes)
fig, ax = plt.subplots(figsize=(6,6))
sns.set(font_scale=1.6)
sns.heatmap(cm, annot=True, ax=ax)