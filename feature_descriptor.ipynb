{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#import helper1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random as rng\n",
    "import os\n",
    "import glob \n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(selected_image):\n",
    "    #selected_image = cv2.resize(selected_image, (0, 0), fx = 0.9, fy = 0.9) \n",
    "    image = cv2.cvtColor(selected_image, cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    #plt.imshow(gray)\n",
    "    cv2.imwrite('B1.jpg',gray)\n",
    "\n",
    "    retval, binary = cv2.threshold(gray,90, 255,0)\n",
    "    #plt.imshow(binary, cmap='gray')\n",
    "    cv2.imwrite('B2.jpg',binary)\n",
    "\n",
    "    edged = cv2.Canny(gray ,15,180) \n",
    "    #plt.imshow(edged, cmap='gray')\n",
    "    #cv2.imwrite('B3.jpg',edged)\n",
    "    return(binary,edged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contourrr(image,binary):\n",
    "    #retval, contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours, hierarchy = cv2.findContours(binary,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    # Draw all contours on a copy of the original image\n",
    "    contours_image = np.copy(image)\n",
    "    print(len(contours))\n",
    "\n",
    "    contours_image = cv2.drawContours(contours_image, contours, -1, (0,0,255), 3)\n",
    "\n",
    "    #plt.imshow(contours_image)\n",
    "    #cv2.imwrite('B5.jpg',contours_image)\n",
    "    return(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi(image,im_binary,contours,ROI_number):\n",
    "    global roi1,roi2\n",
    "    for c in contours:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        #print(cv2.contourArea(c))\n",
    "        z = cv2.contourArea(c) \n",
    "        if(z>300000 and z<490000):\n",
    "            print('--')\n",
    "            print(cv2.contourArea(c))\n",
    "            img = cv2.rectangle(image,(x-30,y-30),(x+w+30,y+h+30),(0,255,0),3)\n",
    "            roi1 = image[y-30:y+h+30,x-30:x+w+30]\n",
    "            #cv2.imwrite('B1000.jpg',roi1)\n",
    "        elif(z>80000 and z<300000):\n",
    "            print('--')\n",
    "            print(cv2.contourArea(c))\n",
    "            img = cv2.rectangle(image,(x-10,y-20),(x+w+20,y+h+20),(0,255,0),3)\n",
    "            roi2 = im_binary[y-20:y+h+20,x-20:x+w+20]\n",
    "            #cv2.imwrite('B1011.jpg',roi2)\n",
    "    \n",
    "    #cv2.imwrite(\"0,1/Color_image\"+str(ROI_number)+\".jpg\",roi1)\n",
    "    \n",
    "    #print('*')\n",
    "    #print(ROI_number)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #plt.imshow(img,cmap='gray')\n",
    "    #cv2.imwrite('B6.jpg',img)\n",
    "    \n",
    "    return(roi1,roi2,img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"0,1/train/\"\n",
    "test_dir = \"0,1/test/\"\n",
    "\n",
    "def loadtrain_dataset(image_dir):\n",
    "    ROI_number = 1\n",
    "    train_images = []\n",
    "    train_labels = [] \n",
    "    # Populate this empty image list\n",
    "    image_types = [\"Defected\",\"Ok\"]\n",
    "    \n",
    "    # Iterate through each color folder\n",
    "    for im_type in image_types:\n",
    "        \n",
    "        # Iterate through each image file in each image_type folder\n",
    "        # glob reads in any image with the extension \"image_dir/im_type/*\"\n",
    "        for file in glob.glob(os.path.join(image_dir, im_type, \"*\")):\n",
    "            \n",
    "            # Read in the image\n",
    "            im = cv2.imread(file)\n",
    "            # Check if the image exists/if it's been correctly read-in\n",
    "            if not im is None:\n",
    "                # Append the image, and it's type to the image list\n",
    "                #image = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                #gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "                im_binary,im_canny = canny(im)\n",
    "                contours = contourrr(im,im_binary)\n",
    "                roi_u,roi_l,total = roi(im,im_binary,contours,ROI_number)\n",
    "                train_images.append(roi_u)\n",
    "                train_labels.append(im_type)\n",
    "                #train_images.append(roi_l)\n",
    "                #train_labels.append(im_type)\n",
    "                #i_list.append((roi_u,im_type))\n",
    "                #i_list.append((roi_l,im_type))\n",
    "                #flat_1 = np.array(roi_u).flatten()\n",
    "                #flat_2 = np.array(roi_l).flatten()\n",
    "                #svm_list.append((flat_1,im_type))\n",
    "                #svm_list.append((flat_2,im_type))\n",
    "                ROI_number += 1\n",
    "                \n",
    "    print(ROI_number)\n",
    "    train_images = np.array(train_images,dtype=object)\n",
    "    train_labels = np.array(train_labels,dtype=object)\n",
    "    return train_images,train_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "--\n",
      "342613.0\n",
      "--\n",
      "98299.0\n",
      "29\n",
      "--\n",
      "316707.5\n",
      "--\n",
      "96080.5\n",
      "12\n",
      "--\n",
      "337288.0\n",
      "--\n",
      "89245.5\n",
      "4\n",
      "8\n",
      "--\n",
      "354620.0\n",
      "--\n",
      "96770.0\n",
      "2\n",
      "23\n",
      "--\n",
      "316726.0\n",
      "--\n",
      "98399.0\n",
      "3\n",
      "41\n",
      "--\n",
      "307624.0\n",
      "--\n",
      "100838.0\n",
      "4\n",
      "19\n",
      "--\n",
      "311736.5\n",
      "--\n",
      "97579.0\n",
      "5\n",
      "7\n",
      "--\n",
      "323697.5\n",
      "--\n",
      "96353.5\n",
      "6\n",
      "16\n",
      "--\n",
      "312454.0\n",
      "--\n",
      "95899.5\n",
      "7\n",
      "11\n",
      "--\n",
      "313312.0\n",
      "--\n",
      "100379.0\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "def loadtest_dataset(image_dir):\n",
    "    ROI_number = 1\n",
    "    test_images = []\n",
    "    test_labels = [] \n",
    "    i_list = []\n",
    "    image_types = [\"Defected\",\"Ok\"]\n",
    "    \n",
    "    # Iterate through each color folder\n",
    "    for im_type in image_types:\n",
    "        \n",
    "        for file in glob.glob(os.path.join(image_dir, im_type, \"*\")):\n",
    "            \n",
    "            # Read in the image\n",
    "            im = mpimg.imread(file)\n",
    "            # Check if the image exists/if it's been correctly read-in\n",
    "            if not im is None:\n",
    "                im_binary,im_canny = canny(im)\n",
    "                contours = contourrr(im,im_binary)\n",
    "                roi_u,roi_l,total = roi(im,im_binary,contours,ROI_number)\n",
    "                test_images.append(roi_u)\n",
    "                test_labels.append(im_type)\n",
    "                #test_images.append(roi_l)\n",
    "                #test_labels.append(im_type)\n",
    "                #i_list.append((roi_u,im_type))\n",
    "                #i_list.append((roi_l,im_type))\n",
    "                #flat_1 = np.array(roi_u).flatten()\n",
    "                #flat_2 = np.array(roi_l).flatten()\n",
    "                #svm_list.append((flat_1,im_type))\n",
    "                #svm_list.append((flat_2,im_type))\n",
    "                ROI_number += 1\n",
    "                print(ROI_number)\n",
    "    \n",
    "    test_images = np.array(test_images,dtype=object)\n",
    "    test_labels = np.array(test_labels,dtype=object)\n",
    "    return test_images,test_labels\n",
    "\n",
    "\n",
    "train_images,train_labels = loadtrain_dataset(train_dir)\n",
    "test_images,test_labels = loadtest_dataset(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "print(train_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "plt.imshow(x_train[0])\n",
    "img = x_train[0]\n",
    "\n",
    "orb = cv2.ORB(nFeatures = 100)\n",
    "kp = orb.detect(img,None)\n",
    "kp, des = orb.compute(img, kp)\n",
    "len(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(dataset):\n",
    "    x_train = dataset\n",
    "    image_dataset = pd.DataFrame()\n",
    "    for image in range(x_train.shape[0]):  #iterate through each file \n",
    "        #print(image)\n",
    "        \n",
    "        df = pd.DataFrame()  #Temporary data frame to capture information for each loop.\n",
    "        #Reset dataframe to blank after each loop.\n",
    "        \n",
    "        input_img = x_train[image]\n",
    "        img = input_img\n",
    "\n",
    "    #Add feature extractors, e.g. edge detection, smoothing, etc. \n",
    "            \n",
    "        # FEATURE 1 - Pixel values\n",
    "         \n",
    "        #Add pixel values to the data frame\n",
    "        pixel_values = img.reshape(-1)\n",
    "        df['Pixel_Value'] = pixel_values   #Pixel value itself as a feature\n",
    "        #df['Image_Name'] = image   #Capture image name as we read multiple images\n",
    "        \n",
    "        # FEATURE 2 - Bunch of Gabor filter responses\n",
    "        \n",
    "        #Generate Gabor features\n",
    "        #num = 1  #To count numbers up in order to give Gabor features a lable in the data frame\n",
    "        #kernels = []\n",
    "        #for theta in range(2):   #Define number of thetas\n",
    "        #    theta = theta / 4. * np.pi\n",
    "        #    for sigma in (1, 3):  #Sigma with 1 and 3\n",
    "        #        lamda = np.pi/4\n",
    "        #        gamma = 0.5\n",
    "        #        gabor_label = 'Gabor' + str(num)  #Label Gabor columns as Gabor1, Gabor2, etc.\n",
    "    #                print(gabor_label)\n",
    "        #        ksize=9\n",
    "        #        kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, 0, ktype=cv2.CV_32F)    \n",
    "        #        kernels.append(kernel)\n",
    "        #        #Now filter the image and add values to a new column \n",
    "        #        fimg = cv2.filter2D(img, cv2.CV_8UC3, kernel)\n",
    "        #        filtered_img = fimg.reshape(-1)\n",
    "        #        df[gabor_label] = filtered_img  #Labels columns as Gabor1, Gabor2, etc.\n",
    "        #        print(gabor_label, ': theta=', theta, ': sigma=', sigma, ': lamda=', lamda, ': gamma=', gamma)\n",
    "        #        num += 1  #Increment for gabor column label\n",
    "                \n",
    "         \n",
    "        #feature 3\n",
    "        #hog = cv2.HOGDescriptor()\n",
    "        #h = hog.compute(img)\n",
    "        #df['HOG'] = h\n",
    "       \n",
    "        #feature4\n",
    "        orb = cv2.ORB()\n",
    "        kp = orb.detect(img,None)\n",
    "        kp, des = orb.compute(img, kp)\n",
    "        df['ORB'] = des\n",
    "        \n",
    "        #Append features from current image to the dataset\n",
    "        image_dataset = image_dataset.append(df)\n",
    "        \n",
    "    return image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-585908163513>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimage_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Reshape to a vector for Random Forest / SVM training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimage_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "image_features = feature_extractor(x_train)\n",
    "\n",
    "#Reshape to a vector for Random Forest / SVM training\n",
    "n_features = image_features.shape[1]\n",
    "image_features = np.expand_dims(image_features, axis=0)\n",
    "X_for_RF = np.reshape(image_features, (x_train.shape[0], -1))  #Reshape to #images, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
    "\n",
    "#Can also use SVM but RF is faster and may be more accurate.\n",
    "#from sklearn import svm\n",
    "#SVM_model = svm.SVC(decision_function_shape='ovo')  #For multiclass classification\n",
    "#SVM_model.fit(X_for_RF, y_train)\n",
    "\n",
    "\n",
    "# Fit the model on training data\n",
    "RF_model.fit(X_for_RF, y_train) #For sklearn no one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on Test data\n",
    "#Extract features from test data and reshape, just like training data\n",
    "test_features = feature_extractor(x_test)\n",
    "test_features = np.expand_dims(test_features, axis=0)\n",
    "test_for_RF = np.reshape(test_features, (x_test.shape[0], -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on test\n",
    "test_prediction = RF_model.predict(test_for_RF)\n",
    "#Inverse le transform to get original label back. \n",
    "test_prediction = le.inverse_transform(test_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print overall accuracy\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(test_labels, test_prediction))\n",
    "\n",
    "#Print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_labels, test_prediction)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))         # Sample figsize in inches\n",
    "sns.set(font_scale=1.6)\n",
    "sns.heatmap(cm, annot=True, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check results on a few random images\n",
    "import random\n",
    "n=random.randint(0, x_test.shape[0]-1) #Select the index of image to be loaded for testing\n",
    "img = x_test[n]\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract features and reshape to right dimensions\n",
    "input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "input_img_features=feature_extractor(input_img)\n",
    "input_img_features = np.expand_dims(input_img_features, axis=0)\n",
    "input_img_for_RF = np.reshape(input_img_features, (input_img.shape[0], -1))\n",
    "\n",
    "\n",
    "#Predict\n",
    "img_prediction = RF_model.predict(input_img_for_RF)\n",
    "img_prediction = le.inverse_transform([img_prediction])  #Reverse the label encoder to original name\n",
    "print(\"The prediction for this image is: \", img_prediction)\n",
    "print(\"The actual label for this image is: \", test_labels[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rng.shuffle(IMAGE_LIST)\n",
    "\n",
    "#cv2.imwrite('1.jpg',selected_image)\n",
    "#image = cv2.cvtColor(selected_image, cv2.COLOR_BGR2RGB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#image_index = 6\n",
    "#selected_image = IMAGE_LIST[image_index][0]\n",
    "#selected_label = IMAGE_LIST[image_index][1]\n",
    "\n",
    "#print('1. The shape of the image',selected_image.shape)\n",
    "#print(' 2. The image label:',selected_label)\n",
    "3#print(selected_image)\n",
    "#plt.imshow(selected_image)\n",
    "#sele = np.array(IMAGE_LIST[:][0],dtype = object)\n",
    "#sele1 = sele.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roi1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
